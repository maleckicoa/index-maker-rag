{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules,  Avoid Sleep Mode,  Reload Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo4j+s://461e473a.databases.neo4j.io\n",
      "neo4j+s://461e473a.databases.neo4j.io\n",
      "Caffeinate started to prevent sleep mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.stop_caffeinate()>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "import importlib\n",
    "import utils.db_funcs\n",
    "import utils.df_funcs\n",
    "import utils.fmp_funcs\n",
    "import utils.graph_db_funcs\n",
    "\n",
    "importlib.reload(utils.db_funcs)\n",
    "importlib.reload(utils.df_funcs) \n",
    "importlib.reload(utils.fmp_funcs) \n",
    "importlib.reload(utils.graph_db_funcs)\n",
    "\n",
    "\n",
    "from utils import db_funcs as db\n",
    "from utils.df_funcs import *\n",
    "from utils.fmp_funcs import *\n",
    "from utils.graph_db_funcs import *\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import atexit\n",
    "caffeinate_process = subprocess.Popen([\"caffeinate\", \"-i\"])\n",
    "print(\"Caffeinate started to prevent sleep mode.\")\n",
    "def stop_caffeinate():\n",
    "    caffeinate_process.terminate()\n",
    "    print(\"Caffeinate stopped. Sleep mode enabled.\")\n",
    "atexit.register(stop_caffeinate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all data from SQLITE, Make FX Conversion to EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run initiated\n",
      "SQLITE Data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Run initiated\")\n",
    "\n",
    "conn = sqlite3.connect(db.db_file)\n",
    "forex_rates = pd.read_sql_query(\"SELECT * FROM exchange_rates\", conn).sort_values(by=['date'], ascending=False).reset_index(drop=True)   \n",
    "stock_info  = pd.read_sql_query(\"SELECT * FROM stock_info\", conn)\n",
    "stock_prices = pd.read_sql_query(\"SELECT * FROM hist_prices\", conn).sort_values(by=['date'], ascending=False).reset_index(drop=True)   \n",
    "stock_mcaps = pd.read_sql_query(\"SELECT * FROM hist_mcaps\", conn).sort_values(by=['date'], ascending=False).reset_index(drop=True)\n",
    "print(\"SQLITE Data loaded\")\n",
    "\n",
    "forex_rates['EUREUR'] = 1\n",
    "stock_info, long_stock_info = transform_stock_info(stock_info, forex_rates, country_codes, stock_subset=16000)\n",
    "stock_prices = transpose_df(stock_prices, values='close')\n",
    "stock_mcaps = transpose_df(stock_mcaps, values='mcap')\n",
    "#all_symbols_16000 = stock_info.symbol.to_list()\n",
    "#with open(\"files/all_symbols_16000.pkl\", \"wb\") as file:\n",
    "#    pickle.dump(all_symbols_16000, file)\n",
    "print(\"Data transformed\")\n",
    "\n",
    "\n",
    "stock_ccy_dict = dict(zip(stock_info['symbol'], stock_info['currency']))\n",
    "mapping_dict = {key: 'EUR' + value for key, value in stock_ccy_dict.items()}\n",
    "\n",
    "price_columns = OrderedSet(stock_prices.columns) & OrderedSet(stock_info.symbol)\n",
    "mcaps_columns = OrderedSet(stock_mcaps.columns) & OrderedSet(stock_info.symbol)\n",
    "\n",
    "stock_prices = stock_prices[['date'] + list(price_columns)]\n",
    "stock_mcaps = stock_mcaps[['date'] + list(mcaps_columns)]\n",
    "\n",
    "stock_prices_eur = fx_converter(stock_prices, forex_rates, mapping_dict)\n",
    "stock_mcaps_eur = fx_converter(stock_mcaps, forex_rates, mapping_dict)\n",
    "print(\"Prices converted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Features, Calculate Returns, Trimming Prices, Save Clean Date to PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misaligned Stocks:  13876\n",
      "Number of Stocks for which NaN were introduced:  603\n",
      "Number of Stocks dropped in both Dataframes:  370 \n",
      "\n",
      "Number of misaligned Stocks:  13506\n",
      "Number of Stocks for which NaN were introduced:  0\n",
      "Number of Stocks dropped in both Dataframes:  0 \n",
      "\n",
      "Stock number before trimming:  13507 13507\n",
      "Stock number after trimming:  13358 13358\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pc_final_inter, mc_final_inter = process_data(stock_prices_eur, stock_mcaps_eur, gap_size=50)\n",
    "#pc_final_inter, mc_final_inter = process_data(stock_prices, stock_mcaps, gap_size=50)\n",
    "prices, mcaps = align_prices_and_mcaps(pc_final_inter, mc_final_inter)\n",
    "_, _, _ = make_comparison_tables(prices, mcaps)\n",
    "prices_trimmed, mcaps_trimmed, removed_stocks = trim_stocks_with_little_data(prices, mcaps, days=250)\n",
    "\n",
    "data_points = calculate_number_of_price_data_points(prices_trimmed)\n",
    "annual_returns = calculate_annualized_returns(prices_trimmed)\n",
    "annual_vols = calculate_annualized_volatilities(prices_trimmed)\n",
    "mcap_dict = dict(zip(stock_info['symbol'], stock_info['market_cap_euro']))\n",
    "trade_volume_dict = dict(zip(stock_info['symbol'], stock_info['avg_trade_vol_euro']))\n",
    "\n",
    "return_bins = make_bins(annual_returns)\n",
    "vol_bins = make_bins(annual_vols)\n",
    "mcap_bins = make_bins(mcap_dict)\n",
    "trade_vol_bins = make_bins(trade_volume_dict)\n",
    "\n",
    "stock_info[\"data_points\"] = stock_info[\"symbol\"].map(data_points)\n",
    "stock_info[\"return_coeff\"] = stock_info[\"symbol\"].map(annual_returns)\n",
    "stock_info[\"volatility_coeff\"] = stock_info[\"symbol\"].map(annual_vols)\n",
    "\n",
    "stock_info['description'] = stock_info.apply( lambda row: f\"Name: {row['name']}, Symbol: {row['symbol']}, Country: {row['country']}, Description: {row['description']}\",axis=1)\n",
    "stock_info[\"return\"] = stock_info[\"symbol\"].map(return_bins)\n",
    "stock_info[\"volatility\"] = stock_info[\"symbol\"].map(vol_bins)\n",
    "stock_info[\"market_capitalization\"] = stock_info[\"symbol\"].map(mcap_bins)\n",
    "stock_info[\"average_trading_volume\"] = stock_info[\"symbol\"].map(trade_vol_bins)\n",
    "\n",
    "stock_info_final = stock_info[stock_info['symbol'].isin(list(prices_trimmed.columns)[1:])]\n",
    "\n",
    "# with open(\"files/stock_info_final.pkl\", \"wb\") as file:\n",
    "#    pickle.dump(stock_info_final, file)\n",
    "\n",
    "# with open(\"files/prices_trimmed.pkl\", \"wb\") as file:\n",
    "#    pickle.dump(prices_trimmed, file)\n",
    "\n",
    "# with open(\"files/mcaps_trimmed.pkl\", \"wb\") as file:\n",
    "#    pickle.dump(mcaps_trimmed, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_info_final.head(5)\n",
    "#prices_trimmed.iloc[:,:20] .head(100)\n",
    "\n",
    "#prices_trimmed[prices_trimmed['date']>='2019-01-01'].iloc[:,:10].head(1000)\n",
    "# annual_returns\n",
    "\n",
    "# max_value = min(data_points.values())\n",
    "\n",
    "# keys_with_max_value = [key for key, value in data_points.items() if value == max_value]\n",
    "# keys_with_max_value\n",
    "\n",
    "# with open('../files/prices_trimmed.pkl', 'rb') as file:\n",
    "#     prices = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
